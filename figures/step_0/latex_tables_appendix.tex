% Appendix Tables - Complete Analysis Results
% Add \usepackage{booktabs} to your LaTeX preamble

% ========== LEXICAL DIVERSITY ==========
\begin{table}[htbp]
\centering
\caption{Lexical Diversity Metrics by Model}
\label{tab:lexical_diversity}
\begin{tabular}{lcc}
\toprule
Model & TTR & Avg. Sentence Length \\
\midrule
RWKV-4-Raven-14B & 0.57 (0.21) & 23.68 (26.35) \\
alpaca-13b & 0.72 (0.18) & 20.33 (16.29) \\
chatglm-6b & 0.54 (0.19) & 25.34 (24.85) \\
claude-v1 & 0.55 (0.19) & 20.89 (20.42) \\
gpt-3.5-turbo & 0.62 (0.18) & 22.42 (15.83) \\
gpt-4 & 0.60 (0.19) & 23.45 (27.38) \\
koala-13b & 0.54 (0.21) & 24.27 (18.44) \\
oasst-pythia-12b & 0.60 (0.20) & 23.38 (22.86) \\
palm-2 & 0.55 (0.22) & 19.63 (13.41) \\
vicuna-13b & 0.56 (0.18) & 24.78 (21.36) \\
\bottomrule
\end{tabular}
\end{table}

% ========== PART-OF-SPEECH TAGS ==========
\begin{table}[htbp]
\centering
\caption{Content Word POS Distribution (per 1000 tokens)}
\label{tab:pos_content_appendix}
\begin{tabular}{lccccc}
\toprule
Model & NOUN & VERB & ADJ & ADV & PROPN \\
\midrule
RWKV-4-Raven-14B & 192.62 (72.40) & 98.21 (48.29) & 65.62 (43.73) & 23.83 (24.28) & 52.40 (78.48) \\
alpaca-13b & 189.61 (84.74) & 99.27 (54.89) & 66.56 (54.45) & 26.36 (30.77) & 59.82 (94.40) \\
chatglm-6b & 194.20 (64.68) & 99.09 (40.68) & 66.48 (37.51) & 24.71 (21.76) & 44.07 (59.89) \\
claude-v1 & 203.86 (63.48) & 105.02 (44.35) & 69.53 (40.83) & 29.24 (24.32) & 60.53 (79.85) \\
gpt-3.5-turbo & 194.25 (68.20) & 98.88 (42.53) & 66.09 (42.98) & 26.30 (25.27) & 57.50 (80.86) \\
gpt-4 & 199.29 (66.70) & 99.19 (43.34) & 66.52 (41.02) & 24.19 (22.92) & 63.71 (81.25) \\
koala-13b & 194.53 (71.65) & 97.75 (43.00) & 65.29 (40.43) & 23.34 (23.14) & 48.54 (73.68) \\
oasst-pythia-12b & 193.48 (75.63) & 99.77 (48.16) & 65.84 (43.88) & 25.66 (27.66) & 55.86 (87.16) \\
palm-2 & 178.36 (58.94) & 102.31 (42.99) & 54.13 (38.75) & 30.40 (22.34) & 43.14 (63.46) \\
vicuna-13b & 195.45 (67.93) & 99.24 (41.03) & 67.49 (39.46) & 25.29 (21.93) & 49.04 (68.14) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Function Word POS Distribution (per 1000 tokens)}
\label{tab:pos_function_appendix}
\begin{tabular}{lccccccc}
\toprule
Model & DET & ADP & PRON & AUX & CCONJ & SCONJ & PART \\
\midrule
RWKV-4-Raven-14B & 88.21 (47.72) & 81.07 (41.25) & 68.81 (59.03) & 61.82 (37.67) & 34.48 (26.32) & 15.15 (20.95) & 26.01 (25.37) \\
alpaca-13b & 84.85 (54.36) & 80.70 (48.04) & 67.69 (67.00) & 65.01 (45.31) & 32.40 (29.47) & 14.50 (24.47) & 24.28 (28.99) \\
chatglm-6b & 86.58 (42.08) & 82.06 (37.66) & 70.59 (54.56) & 63.84 (35.20) & 37.05 (25.43) & 18.21 (21.34) & 28.34 (23.44) \\
claude-v1 & 74.48 (38.54) & 76.83 (33.27) & 53.68 (42.99) & 46.20 (29.74) & 31.95 (24.79) & 11.76 (13.22) & 22.08 (22.81) \\
gpt-3.5-turbo & 79.48 (43.73) & 81.67 (38.14) & 66.22 (54.77) & 57.44 (35.87) & 34.85 (25.88) & 15.90 (20.46) & 25.33 (22.64) \\
gpt-4 & 77.09 (40.85) & 79.10 (38.18) & 54.31 (47.31) & 44.77 (31.71) & 34.57 (24.01) & 14.95 (18.70) & 22.41 (20.53) \\
koala-13b & 85.92 (45.16) & 82.06 (39.90) & 69.73 (56.58) & 61.89 (36.41) & 36.59 (24.96) & 16.47 (21.17) & 26.81 (24.33) \\
oasst-pythia-12b & 86.97 (49.41) & 80.73 (42.71) & 69.45 (62.60) & 63.18 (41.38) & 35.09 (26.69) & 15.52 (21.57) & 25.76 (27.44) \\
palm-2 & 83.10 (38.70) & 81.73 (42.73) & 82.64 (61.11) & 70.63 (32.37) & 31.73 (25.64) & 18.09 (20.93) & 33.67 (28.24) \\
vicuna-13b & 85.92 (42.94) & 84.33 (37.86) & 67.19 (52.65) & 60.16 (35.46) & 37.93 (25.11) & 15.92 (18.69) & 26.35 (22.29) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Miscellaneous POS Distribution (per 1000 tokens)}
\label{tab:pos_misc_appendix}
\begin{tabular}{lccccc}
\toprule
Model & PUNCT & NUM & SYM & INTJ & X \\
\midrule
RWKV-4-Raven-14B & 148.26 (88.12) & 25.35 (59.32) & 3.48 (16.56) & 5.21 (16.37) & 9.46 (23.54) \\
alpaca-13b & 147.77 (89.90) & 26.07 (56.32) & 2.37 (13.51) & 7.06 (23.34) & 5.67 (22.51) \\
chatglm-6b & 143.01 (80.78) & 24.22 (57.02) & 3.68 (16.66) & 4.74 (16.10) & 9.11 (20.21) \\
claude-v1 & 160.48 (87.51) & 33.45 (63.55) & 5.92 (19.57) & 2.12 (8.63) & 12.85 (20.37) \\
gpt-3.5-turbo & 152.26 (86.28) & 25.34 (55.20) & 3.52 (14.83) & 4.60 (15.01) & 10.39 (21.90) \\
gpt-4 & 167.89 (85.95) & 31.20 (64.81) & 3.97 (14.83) & 4.03 (14.02) & 12.81 (22.54) \\
koala-13b & 149.50 (90.33) & 23.78 (56.85) & 3.03 (13.61) & 5.54 (20.41) & 9.22 (21.07) \\
oasst-pythia-12b & 142.67 (81.93) & 24.99 (55.54) & 3.18 (14.98) & 4.49 (16.52) & 7.35 (20.39) \\
palm-2 & 149.18 (87.85) & 24.46 (55.33) & 5.55 (22.83) & 5.14 (14.53) & 5.72 (16.13) \\
vicuna-13b & 145.27 (83.60) & 22.98 (51.58) & 3.49 (15.20) & 3.97 (14.10) & 9.97 (23.92) \\
\bottomrule
\end{tabular}
\end{table}

% ========== COMPLETE FUNCTION WORD TABLES ==========

% --- Pronouns ---
\begin{table}[htbp]
\centering
\caption{Pronouns Usage (mean count per response) (Part 1/2)}
\label{tab:fw_pronouns_part1}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{i} & \textit{you} & \textit{he} & \textit{she} & \textit{it} & \textit{we} \\
\midrule
RWKV-4-Raven-14B & 11.32 (26.82) & 12.15 (24.95) & 1.20 (6.43) & 0.69 (5.41) & 9.23 (14.71) & 1.46 (6.56) \\
alpaca-13b & 9.63 (28.10) & 12.42 (28.94) & 2.01 (10.01) & 0.83 (6.08) & 10.48 (20.79) & 0.79 (5.75) \\
chatglm-6b & 10.03 (23.57) & 13.17 (24.95) & 1.25 (6.31) & 0.89 (6.11) & 9.80 (13.24) & 1.19 (5.28) \\
claude-v1 & 10.04 (26.56) & 7.54 (14.43) & 1.06 (5.44) & 0.55 (3.78) & 5.03 (8.97) & 1.13 (4.60) \\
gpt-3.5-turbo & 10.65 (24.13) & 11.28 (22.74) & 1.25 (6.97) & 0.87 (5.83) & 8.38 (13.40) & 1.86 (7.45) \\
gpt-4 & 7.52 (18.83) & 9.98 (20.77) & 0.98 (5.53) & 0.57 (4.20) & 6.19 (10.69) & 1.62 (6.39) \\
koala-13b & 10.89 (26.17) & 12.33 (24.61) & 1.50 (7.47) & 0.52 (4.17) & 9.83 (14.47) & 1.08 (5.40) \\
oasst-pythia-12b & 9.83 (25.78) & 12.47 (25.76) & 1.66 (8.44) & 0.86 (5.99) & 8.74 (15.79) & 1.57 (8.68) \\
palm-2 & 16.61 (27.34) & 12.89 (22.35) & 1.59 (7.94) & 0.62 (4.98) & 7.72 (12.08) & 1.43 (5.86) \\
vicuna-13b & 9.82 (22.85) & 11.38 (22.46) & 1.10 (5.75) & 0.73 (5.09) & 9.12 (13.12) & 1.37 (6.64) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Pronouns Usage (mean count per response) (Part 2/2)}
\label{tab:fw_pronouns_part2}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{they} & \textit{me} & \textit{him} & \textit{her} & \textit{us} & \textit{them} \\
\midrule
RWKV-4-Raven-14B & 1.95 (6.98) & 1.24 (6.69) & 0.20 (1.85) & 0.74 (5.17) & 0.36 (2.98) & 0.90 (3.94) \\
alpaca-13b & 2.10 (9.59) & 0.80 (5.64) & 0.36 (3.54) & 0.97 (6.61) & 0.49 (4.22) & 1.00 (5.08) \\
chatglm-6b & 2.32 (7.01) & 1.22 (5.60) & 0.22 (2.09) & 0.72 (4.82) & 0.28 (2.25) & 0.83 (3.38) \\
claude-v1 & 1.75 (5.40) & 1.85 (4.42) & 0.24 (1.77) & 0.64 (4.49) & 0.42 (3.09) & 0.73 (2.58) \\
gpt-3.5-turbo & 2.04 (6.91) & 1.07 (6.22) & 0.21 (1.75) & 0.85 (6.93) & 0.43 (3.13) & 0.91 (3.80) \\
gpt-4 & 1.94 (6.39) & 1.00 (6.23) & 0.23 (1.99) & 0.78 (5.36) & 0.23 (1.74) & 0.86 (3.46) \\
koala-13b & 2.15 (7.42) & 1.21 (5.94) & 0.26 (2.32) & 0.68 (4.75) & 0.28 (2.09) & 0.85 (3.26) \\
oasst-pythia-12b & 2.39 (9.59) & 0.88 (5.71) & 0.29 (2.36) & 0.78 (5.56) & 0.43 (3.60) & 0.90 (4.02) \\
palm-2 & 2.48 (6.86) & 0.88 (5.89) & 0.19 (1.51) & 0.37 (2.84) & 2.18 (7.90) & 0.81 (3.53) \\
vicuna-13b & 2.07 (6.37) & 1.22 (6.20) & 0.18 (1.76) & 0.89 (5.48) & 0.42 (3.09) & 0.91 (3.64) \\
\bottomrule
\end{tabular}
\end{table}

% --- Prepositions ---
\begin{table}[htbp]
\centering
\caption{Prepositions Usage (mean count per response) (Part 1/2)}
\label{tab:fw_prepositions_part1}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{in} & \textit{on} & \textit{at} & \textit{to} & \textit{from} & \textit{with} \\
\midrule
RWKV-4-Raven-14B & 12.88 (17.70) & 4.92 (10.00) & 1.17 (4.96) & 24.52 (23.48) & 2.19 (6.68) & 6.14 (11.93) \\
alpaca-13b & 12.83 (20.58) & 4.20 (10.98) & 1.18 (6.61) & 24.79 (28.03) & 3.15 (10.96) & 5.33 (12.89) \\
chatglm-6b & 13.19 (14.96) & 5.16 (8.54) & 1.27 (4.59) & 27.27 (22.10) & 2.40 (5.92) & 5.78 (9.71) \\
claude-v1 & 11.67 (14.08) & 4.71 (8.24) & 1.97 (5.73) & 18.64 (17.51) & 3.03 (7.01) & 4.84 (7.69) \\
gpt-3.5-turbo & 12.47 (16.77) & 5.36 (10.45) & 1.06 (4.71) & 24.02 (21.50) & 2.72 (7.65) & 6.21 (11.41) \\
gpt-4 & 12.00 (14.72) & 4.87 (9.67) & 1.51 (5.86) & 21.18 (17.96) & 2.28 (6.53) & 6.41 (11.16) \\
koala-13b & 12.58 (16.70) & 5.37 (9.60) & 1.21 (4.65) & 25.13 (21.55) & 2.32 (6.69) & 6.06 (10.74) \\
oasst-pythia-12b & 12.16 (17.32) & 5.06 (11.01) & 1.24 (6.02) & 25.46 (24.65) & 2.79 (8.64) & 5.38 (10.82) \\
palm-2 & 10.78 (14.40) & 3.82 (7.05) & 5.24 (12.88) & 30.24 (25.15) & 2.16 (5.61) & 9.87 (14.32) \\
vicuna-13b & 13.20 (14.79) & 5.41 (8.82) & 1.22 (4.68) & 25.55 (19.99) & 2.26 (5.41) & 5.92 (9.81) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Prepositions Usage (mean count per response) (Part 2/2)}
\label{tab:fw_prepositions_part2}
\begin{tabular}{lcccc}
\toprule
Model & \textit{by} & \textit{of} & \textit{for} & \textit{about} \\
\midrule
RWKV-4-Raven-14B & 3.46 (8.94) & 21.84 (24.77) & 7.43 (12.07) & 1.74 (8.66) \\
alpaca-13b & 3.35 (10.39) & 20.44 (26.70) & 7.77 (15.69) & 1.63 (8.57) \\
chatglm-6b & 3.32 (7.99) & 21.48 (21.10) & 7.30 (10.89) & 2.06 (6.61) \\
claude-v1 & 2.76 (7.09) & 16.25 (18.55) & 8.30 (11.57) & 1.96 (7.09) \\
gpt-3.5-turbo & 3.19 (8.36) & 19.56 (23.02) & 7.53 (11.83) & 1.58 (6.54) \\
gpt-4 & 2.82 (6.15) & 18.25 (21.77) & 7.13 (10.32) & 1.22 (6.20) \\
koala-13b & 3.11 (7.34) & 22.06 (22.18) & 8.08 (11.88) & 1.82 (6.88) \\
oasst-pythia-12b & 3.93 (10.42) & 21.58 (25.31) & 6.94 (12.12) & 1.85 (8.95) \\
palm-2 & 2.62 (6.27) & 21.06 (19.56) & 6.11 (8.92) & 1.66 (5.46) \\
vicuna-13b & 3.50 (7.95) & 22.46 (21.81) & 7.46 (10.18) & 1.89 (6.64) \\
\bottomrule
\end{tabular}
\end{table}

% --- Articles_Determiners ---
\begin{table}[htbp]
\centering
\caption{Articles Determiners Usage (mean count per response) (Part 1/2)}
\label{tab:fw_articles_determiners_part1}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{the} & \textit{a} & \textit{an} & \textit{this} & \textit{that} & \textit{these} \\
\midrule
RWKV-4-Raven-14B & 51.17 (41.89) & 25.63 (27.03) & 3.07 (8.28) & 3.65 (7.50) & 10.00 (13.72) & 0.89 (3.25) \\
alpaca-13b & 50.00 (47.54) & 23.79 (29.86) & 4.08 (12.01) & 3.17 (12.76) & 7.53 (16.02) & 0.49 (2.86) \\
chatglm-6b & 49.48 (37.87) & 25.61 (24.48) & 2.60 (6.73) & 4.39 (9.19) & 10.91 (12.59) & 0.80 (2.55) \\
claude-v1 & 40.81 (33.50) & 18.40 (19.17) & 3.12 (6.56) & 4.85 (8.25) & 6.85 (12.23) & 0.80 (2.40) \\
gpt-3.5-turbo & 45.46 (39.18) & 20.76 (22.71) & 3.86 (8.65) & 3.73 (7.58) & 8.44 (11.50) & 0.81 (2.91) \\
gpt-4 & 44.12 (36.38) & 19.68 (22.57) & 3.76 (8.70) & 4.26 (8.09) & 5.56 (8.36) & 1.29 (3.70) \\
koala-13b & 49.81 (40.23) & 24.94 (23.81) & 2.57 (6.40) & 3.63 (8.16) & 10.20 (13.05) & 0.92 (2.78) \\
oasst-pythia-12b & 52.01 (45.12) & 24.54 (26.12) & 2.60 (7.41) & 3.71 (9.18) & 9.85 (14.68) & 0.87 (3.55) \\
palm-2 & 41.19 (37.88) & 27.64 (21.70) & 3.41 (8.55) & 9.94 (13.78) & 14.94 (15.43) & 0.88 (2.69) \\
vicuna-13b & 49.31 (38.17) & 24.61 (21.78) & 2.70 (5.83) & 4.08 (7.72) & 10.18 (11.85) & 0.93 (2.73) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Articles Determiners Usage (mean count per response) (Part 2/2)}
\label{tab:fw_articles_determiners_part2}
\begin{tabular}{lcccc}
\toprule
Model & \textit{those} & \textit{my} & \textit{your} & \textit{their} \\
\midrule
RWKV-4-Raven-14B & 0.19 (1.45) & 1.28 (7.16) & 4.20 (12.47) & 1.74 (5.93) \\
alpaca-13b & 0.32 (3.17) & 1.34 (9.95) & 3.26 (12.66) & 1.75 (7.16) \\
chatglm-6b & 0.16 (1.07) & 1.55 (8.11) & 3.91 (10.27) & 2.00 (6.06) \\
claude-v1 & 0.52 (2.50) & 1.18 (5.78) & 2.96 (8.26) & 1.43 (4.79) \\
gpt-3.5-turbo & 0.28 (2.53) & 1.54 (7.49) & 4.01 (11.34) & 2.22 (6.53) \\
gpt-4 & 0.23 (1.85) & 1.30 (6.27) & 3.71 (9.66) & 2.50 (7.27) \\
koala-13b & 0.18 (1.32) & 1.66 (8.94) & 3.80 (11.34) & 1.94 (6.70) \\
oasst-pythia-12b & 0.24 (2.00) & 1.35 (7.90) & 4.24 (12.71) & 2.06 (7.28) \\
palm-2 & 0.13 (1.74) & 1.00 (5.16) & 5.45 (11.95) & 1.40 (4.98) \\
vicuna-13b & 0.18 (1.48) & 1.60 (7.83) & 3.70 (10.75) & 1.90 (5.49) \\
\bottomrule
\end{tabular}
\end{table}

% --- Conjunctions ---
\begin{table}[htbp]
\centering
\caption{Conjunctions Usage (mean count per response) (Part 1/3)}
\label{tab:fw_conjunctions_part1}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{and} & \textit{or} & \textit{but} & \textit{because} & \textit{although} & \textit{while} \\
\midrule
RWKV-4-Raven-14B & 25.30 (22.55) & 6.20 (12.76) & 1.92 (6.21) & 0.91 (5.56) & 0.00 (0.14) & 0.79 (3.77) \\
alpaca-13b & 26.56 (26.99) & 3.55 (10.64) & 1.44 (6.50) & 0.69 (4.66) & 0.04 (0.87) & 0.85 (4.66) \\
chatglm-6b & 26.22 (22.33) & 7.25 (12.04) & 2.60 (6.44) & 0.98 (5.50) & 0.01 (0.33) & 0.81 (3.33) \\
claude-v1 & 19.95 (18.11) & 6.02 (12.11) & 4.74 (11.94) & 0.20 (1.41) & 0.04 (0.42) & 0.69 (2.28) \\
gpt-3.5-turbo & 25.09 (21.88) & 6.33 (12.22) & 2.63 (7.17) & 0.70 (4.55) & 0.03 (0.40) & 0.80 (3.03) \\
gpt-4 & 24.21 (20.49) & 7.49 (12.67) & 1.61 (5.65) & 0.64 (5.12) & 0.06 (0.75) & 0.83 (2.84) \\
koala-13b & 26.62 (22.29) & 6.63 (12.07) & 2.44 (7.11) & 0.65 (4.20) & 0.02 (0.38) & 0.71 (2.58) \\
oasst-pythia-12b & 27.94 (24.52) & 4.58 (10.58) & 1.62 (5.43) & 0.95 (6.26) & 0.02 (0.72) & 0.79 (3.64) \\
palm-2 & 26.04 (25.15) & 3.17 (6.77) & 1.65 (4.69) & 0.88 (3.86) & 0.01 (0.16) & 0.48 (2.37) \\
vicuna-13b & 27.09 (21.59) & 7.38 (12.84) & 2.52 (6.21) & 0.53 (3.70) & 0.03 (0.50) & 0.81 (2.97) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Conjunctions Usage (mean count per response) (Part 2/3)}
\label{tab:fw_conjunctions_part2}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{if} & \textit{when} & \textit{however} & \textit{therefore} & \textit{moreover} & \textit{furthermore} \\
\midrule
RWKV-4-Raven-14B & 2.27 (7.05) & 0.99 (4.42) & 0.98 (3.42) & 0.29 (2.23) & 0.01 (0.23) & 0.01 (0.24) \\
alpaca-13b & 1.66 (6.60) & 1.10 (6.00) & 0.36 (2.73) & 0.17 (1.73) & 0.01 (0.26) & 0.05 (0.79) \\
chatglm-6b & 3.06 (7.65) & 0.92 (3.70) & 0.85 (2.77) & 0.51 (3.21) & 0.00 (0.00) & 0.02 (0.30) \\
claude-v1 & 3.37 (6.14) & 0.87 (2.88) & 0.34 (1.39) & 0.46 (2.63) & 0.00 (0.00) & 0.00 (0.00) \\
gpt-3.5-turbo & 2.42 (6.71) & 0.77 (3.27) & 1.59 (4.63) & 0.58 (3.16) & 0.01 (0.35) & 0.01 (0.20) \\
gpt-4 & 2.99 (7.38) & 1.02 (3.99) & 1.30 (3.87) & 0.15 (1.75) & 0.00 (0.07) & 0.01 (0.23) \\
koala-13b & 2.64 (6.67) & 0.85 (3.55) & 0.98 (3.25) & 0.33 (2.51) & 0.01 (0.26) & 0.00 (0.13) \\
oasst-pythia-12b & 2.65 (7.87) & 0.88 (3.94) & 0.81 (3.21) & 0.27 (2.09) & 0.00 (0.18) & 0.03 (0.46) \\
palm-2 & 4.74 (9.16) & 0.94 (3.09) & 0.85 (2.48) & 0.37 (2.44) & 0.00 (0.06) & 0.00 (0.05) \\
vicuna-13b & 2.75 (7.36) & 0.86 (3.20) & 1.04 (3.12) & 0.29 (1.74) & 0.00 (0.13) & 0.02 (0.29) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Conjunctions Usage (mean count per response) (Part 3/3)}
\label{tab:fw_conjunctions_part3}
\begin{tabular}{lcc}
\toprule
Model & \textit{nevertheless} & \textit{thus} \\
\midrule
RWKV-4-Raven-14B & 0.00 (0.02) & 0.02 (0.56) \\
alpaca-13b & 0.00 (0.00) & 0.04 (0.71) \\
chatglm-6b & 0.00 (0.00) & 0.00 (0.00) \\
claude-v1 & 0.00 (0.00) & 0.00 (0.10) \\
gpt-3.5-turbo & 0.00 (0.00) & 0.03 (0.58) \\
gpt-4 & 0.00 (0.20) & 0.03 (0.50) \\
koala-13b & 0.00 (0.00) & 0.02 (0.46) \\
oasst-pythia-12b & 0.00 (0.00) & 0.03 (1.21) \\
palm-2 & 0.00 (0.05) & 0.02 (0.75) \\
vicuna-13b & 0.00 (0.00) & 0.00 (0.13) \\
\bottomrule
\end{tabular}
\end{table}

% --- Auxiliary_Verbs ---
\begin{table}[htbp]
\centering
\caption{Auxiliary Verbs Usage (mean count per response) (Part 1/4)}
\label{tab:fw_auxiliary_verbs_part1}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{be} & \textit{am} & \textit{is} & \textit{are} & \textit{was} & \textit{were} \\
\midrule
RWKV-4-Raven-14B & 4.79 (9.71) & 1.59 (9.13) & 19.86 (26.58) & 6.28 (13.38) & 2.54 (10.80) & 0.70 (4.52) \\
alpaca-13b & 5.49 (12.95) & 1.02 (8.66) & 22.04 (33.90) & 6.78 (18.99) & 2.70 (11.75) & 0.49 (3.59) \\
chatglm-6b & 5.78 (9.84) & 0.82 (4.85) & 19.59 (23.88) & 6.09 (11.26) & 2.35 (8.50) & 0.83 (6.46) \\
claude-v1 & 3.70 (7.29) & 0.21 (2.29) & 14.21 (20.49) & 5.77 (9.51) & 1.58 (6.30) & 0.64 (3.19) \\
gpt-3.5-turbo & 4.51 (9.81) & 0.86 (5.14) & 17.40 (25.38) & 5.28 (10.89) & 2.23 (8.84) & 0.56 (3.54) \\
gpt-4 & 3.89 (7.55) & 0.94 (5.40) & 13.06 (21.22) & 3.99 (9.45) & 1.44 (6.81) & 0.39 (2.73) \\
koala-13b & 5.64 (10.11) & 1.13 (6.35) & 18.40 (24.26) & 5.44 (11.65) & 2.52 (9.72) & 0.74 (4.21) \\
oasst-pythia-12b & 5.09 (11.37) & 1.04 (7.33) & 19.04 (27.66) & 5.98 (14.38) & 2.74 (11.54) & 0.66 (4.53) \\
palm-2 & 5.47 (9.13) & 5.32 (14.32) & 21.06 (23.03) & 7.24 (11.58) & 2.26 (8.47) & 0.53 (3.39) \\
vicuna-13b & 5.10 (9.03) & 0.99 (5.55) & 18.60 (21.54) & 5.52 (10.04) & 2.56 (8.88) & 0.57 (3.18) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Auxiliary Verbs Usage (mean count per response) (Part 2/4)}
\label{tab:fw_auxiliary_verbs_part2}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{have} & \textit{has} & \textit{had} & \textit{do} & \textit{does} & \textit{did} \\
\midrule
RWKV-4-Raven-14B & 3.82 (9.58) & 2.74 (14.00) & 0.53 (3.57) & 2.63 (9.91) & 0.51 (3.72) & 0.51 (4.55) \\
alpaca-13b & 3.19 (12.02) & 2.08 (11.79) & 0.56 (3.90) & 2.24 (11.82) & 0.39 (3.37) & 0.79 (6.96) \\
chatglm-6b & 4.49 (10.41) & 2.53 (10.63) & 0.65 (4.36) & 2.37 (8.01) & 0.58 (3.92) & 0.47 (4.61) \\
claude-v1 & 4.70 (8.69) & 2.09 (7.76) & 0.43 (2.46) & 2.95 (9.65) & 0.75 (2.88) & 0.26 (2.88) \\
gpt-3.5-turbo & 3.88 (9.33) & 2.05 (8.67) & 0.52 (3.23) & 2.53 (8.58) & 0.62 (4.67) & 0.57 (4.96) \\
gpt-4 & 3.85 (9.94) & 1.70 (7.51) & 0.29 (2.15) & 1.67 (6.95) & 0.63 (3.97) & 0.35 (3.51) \\
koala-13b & 4.42 (11.67) & 2.05 (8.83) & 0.54 (4.07) & 2.44 (8.27) & 0.45 (4.20) & 0.60 (5.45) \\
oasst-pythia-12b & 3.67 (10.88) & 2.67 (11.77) & 0.54 (3.55) & 3.04 (13.12) & 0.33 (2.97) & 0.69 (6.01) \\
palm-2 & 2.97 (7.63) & 1.57 (5.35) & 0.37 (2.37) & 1.89 (6.53) & 0.57 (3.73) & 0.30 (2.69) \\
vicuna-13b & 4.41 (9.96) & 2.33 (10.45) & 0.49 (3.13) & 2.29 (7.22) & 0.45 (2.40) & 0.33 (3.29) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Auxiliary Verbs Usage (mean count per response) (Part 3/4)}
\label{tab:fw_auxiliary_verbs_part3}
\begin{tabular}{lcccccc}
\toprule
Model & \textit{will} & \textit{would} & \textit{can} & \textit{could} & \textit{should} & \textit{may} \\
\midrule
RWKV-4-Raven-14B & 1.96 (7.22) & 1.68 (7.80) & 8.04 (16.03) & 1.30 (5.96) & 0.83 (6.32) & 1.30 (5.42) \\
alpaca-13b & 2.27 (9.85) & 1.93 (10.20) & 8.65 (19.87) & 1.29 (6.89) & 1.59 (9.15) & 0.89 (6.83) \\
chatglm-6b & 2.19 (6.45) & 1.62 (6.47) & 8.76 (16.83) & 1.36 (5.28) & 0.70 (3.53) & 1.88 (5.31) \\
claude-v1 & 3.07 (9.78) & 1.90 (6.39) & 4.46 (8.53) & 0.93 (3.70) & 0.58 (2.66) & 1.45 (6.18) \\
gpt-3.5-turbo & 1.63 (6.21) & 1.63 (6.86) & 8.64 (16.66) & 1.03 (4.65) & 0.64 (3.91) & 2.15 (7.75) \\
gpt-4 & 1.68 (6.57) & 1.32 (6.27) & 6.42 (13.38) & 0.80 (3.68) & 0.61 (3.38) & 1.63 (5.12) \\
koala-13b & 1.74 (6.14) & 1.75 (7.08) & 8.93 (17.83) & 1.08 (4.26) & 0.48 (4.06) & 2.09 (6.44) \\
oasst-pythia-12b & 2.17 (8.82) & 2.17 (10.64) & 8.07 (16.67) & 1.26 (6.26) & 0.89 (5.01) & 1.65 (6.82) \\
palm-2 & 2.66 (6.89) & 1.33 (5.61) & 6.60 (13.27) & 0.94 (4.34) & 0.63 (3.49) & 0.88 (4.08) \\
vicuna-13b & 1.73 (6.13) & 1.92 (7.77) & 7.47 (14.22) & 1.36 (5.25) & 0.54 (2.91) & 1.99 (6.02) \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Auxiliary Verbs Usage (mean count per response) (Part 4/4)}
\label{tab:fw_auxiliary_verbs_part4}
\begin{tabular}{lc}
\toprule
Model & \textit{might} \\
\midrule
RWKV-4-Raven-14B & 0.19 (1.66) \\
alpaca-13b & 0.28 (2.69) \\
chatglm-6b & 0.39 (3.49) \\
claude-v1 & 0.08 (0.67) \\
gpt-3.5-turbo & 0.25 (1.99) \\
gpt-4 & 0.71 (3.32) \\
koala-13b & 0.29 (1.74) \\
oasst-pythia-12b & 0.22 (1.90) \\
palm-2 & 0.28 (1.81) \\
vicuna-13b & 0.37 (2.14) \\
\bottomrule
\end{tabular}
\end{table}

% --- Particles ---
\begin{table}[htbp]
\centering
\caption{Particles Usage (mean count per response)}
\label{tab:fw_particles}
\begin{tabular}{lcccc}
\toprule
Model & \textit{not} & \textit{up} & \textit{off} & \textit{out} \\
\midrule
RWKV-4-Raven-14B & 4.48 (11.56) & 0.77 (3.95) & 0.21 (2.07) & 0.52 (3.39) \\
alpaca-13b & 3.01 (11.99) & 1.01 (5.55) & 0.20 (3.11) & 0.85 (5.05) \\
chatglm-6b & 4.84 (9.91) & 0.67 (2.89) & 0.17 (1.64) & 0.56 (2.91) \\
claude-v1 & 6.28 (15.55) & 1.15 (4.51) & 0.14 (0.98) & 0.57 (2.13) \\
gpt-3.5-turbo & 4.56 (10.95) & 0.89 (3.78) & 0.17 (1.60) & 0.76 (4.01) \\
gpt-4 & 3.33 (8.80) & 0.91 (4.56) & 0.14 (1.24) & 0.56 (3.35) \\
koala-13b & 4.61 (12.00) & 0.98 (4.43) & 0.17 (1.54) & 0.44 (2.35) \\
oasst-pythia-12b & 3.44 (11.39) & 0.74 (3.27) & 0.19 (1.98) & 0.55 (3.32) \\
palm-2 & 5.49 (11.64) & 0.82 (3.21) & 0.14 (1.20) & 0.61 (3.24) \\
vicuna-13b & 4.61 (10.66) & 0.80 (3.70) & 0.19 (1.64) & 0.53 (2.33) \\
\bottomrule
\end{tabular}
\end{table}

% --- Quantifiers ---
\begin{table}[htbp]
\centering
\caption{Quantifiers Usage (mean count per response)}
\label{tab:fw_quantifiers}
\begin{tabular}{lccccc}
\toprule
Model & \textit{some} & \textit{many} & \textit{few} & \textit{all} & \textit{each} \\
\midrule
RWKV-4-Raven-14B & 1.22 (4.45) & 0.74 (3.62) & 0.29 (2.03) & 0.93 (4.20) & 0.81 (3.54) \\
alpaca-13b & 1.15 (6.19) & 0.63 (4.43) & 0.21 (2.05) & 0.99 (5.81) & 0.70 (4.72) \\
chatglm-6b & 1.35 (4.02) & 1.07 (4.89) & 0.31 (1.53) & 1.02 (3.79) & 1.03 (4.61) \\
claude-v1 & 2.36 (4.68) & 0.96 (3.48) & 0.35 (1.40) & 1.31 (4.18) & 1.15 (4.01) \\
gpt-3.5-turbo & 1.47 (4.12) & 0.76 (3.44) & 0.24 (1.47) & 1.04 (4.11) & 0.93 (4.00) \\
gpt-4 & 1.01 (3.01) & 0.38 (2.03) & 0.12 (0.97) & 0.78 (3.09) & 0.95 (3.78) \\
koala-13b & 1.28 (4.03) & 0.82 (3.97) & 0.28 (1.50) & 0.93 (3.85) & 0.98 (4.10) \\
oasst-pythia-12b & 1.17 (4.05) & 0.81 (3.48) & 0.25 (1.82) & 1.33 (7.07) & 1.03 (6.27) \\
palm-2 & 1.39 (3.35) & 0.77 (2.83) & 0.44 (2.23) & 1.43 (4.38) & 0.90 (3.15) \\
vicuna-13b & 1.29 (4.22) & 0.93 (3.49) & 0.27 (1.45) & 1.03 (4.54) & 0.98 (4.11) \\
\bottomrule
\end{tabular}
\end{table}

% ========== N-GRAM FREQUENCY TABLES ==========

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for RWKV\-4\-Raven\-14B}
\label{tab:unigrams_RWKV_4_Raven_14B}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{use} & 993 \\
\textit{used} & 868 \\
\textit{help} & 646 \\
\textit{time} & 646 \\
\textit{data} & 620 \\
\textit{model} & 616 \\
\textit{make} & 608 \\
\textit{important} & 592 \\
\textit{create} & 585 \\
\textit{sure} & 573 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for RWKV\-4\-Raven\-14B}
\label{tab:bigrams_RWKV_4_Raven_14B}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,447 \\
\textit{in the} & 1,679 \\
\textit{it is} & 1,026 \\
\textit{to the} & 1,017 \\
\textit{and the} & 908 \\
\textit{on the} & 847 \\
\textit{you can} & 736 \\
\textit{can be} & 706 \\
\textit{such as} & 703 \\
\textit{that the} & 496 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for alpaca\-13b}
\label{tab:unigrams_alpaca_13b}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{help} & 372 \\
\textit{used} & 371 \\
\textit{make} & 346 \\
\textit{time} & 329 \\
\textit{use} & 321 \\
\textit{data} & 310 \\
\textit{world} & 242 \\
\textit{like} & 238 \\
\textit{create} & 216 \\
\textit{10} & 215 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for alpaca\-13b}
\label{tab:bigrams_alpaca_13b}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 1,012 \\
\textit{in the} & 667 \\
\textit{it is} & 522 \\
\textit{to the} & 382 \\
\textit{such as} & 369 \\
\textit{on the} & 353 \\
\textit{and the} & 345 \\
\textit{can be} & 337 \\
\textit{you can} & 330 \\
\textit{is the} & 318 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for chatglm\-6b}
\label{tab:unigrams_chatglm_6b}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{use} & 1,319 \\
\textit{used} & 1,180 \\
\textit{data} & 1,172 \\
\textit{years} & 1,050 \\
\textit{important} & 880 \\
\textit{make} & 822 \\
\textit{help} & 811 \\
\textit{time} & 805 \\
\textit{using} & 737 \\
\textit{create} & 645 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for chatglm\-6b}
\label{tab:bigrams_chatglm_6b}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,994 \\
\textit{in the} & 2,090 \\
\textit{it is} & 1,372 \\
\textit{to the} & 1,281 \\
\textit{and the} & 1,117 \\
\textit{on the} & 1,095 \\
\textit{can be} & 969 \\
\textit{years and} & 951 \\
\textit{and years} & 928 \\
\textit{such as} & 903 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for claude\-v1}
\label{tab:unigrams_claude_v1}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{like} & 1,836 \\
\textit{let} & 1,241 \\
\textit{time} & 1,131 \\
\textit{know} & 1,116 \\
\textit{questions} & 831 \\
\textit{use} & 815 \\
\textit{new} & 776 \\
\textit{data} & 767 \\
\textit{make} & 763 \\
\textit{help} & 675 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for claude\-v1}
\label{tab:bigrams_claude_v1}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,366 \\
\textit{in the} & 1,783 \\
\textit{if you} & 1,139 \\
\textit{to the} & 1,041 \\
\textit{on the} & 965 \\
\textit{let me} & 931 \\
\textit{know if} & 915 \\
\textit{me know} & 912 \\
\textit{you have} & 896 \\
\textit{here is} & 721 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for gpt\-3.5\-turbo}
\label{tab:unigrams_gpt_3.5_turbo}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{use} & 726 \\
\textit{time} & 626 \\
\textit{ai} & 584 \\
\textit{model} & 567 \\
\textit{language} & 540 \\
\textit{help} & 538 \\
\textit{data} & 526 \\
\textit{using} & 491 \\
\textit{used} & 490 \\
\textit{make} & 472 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for gpt\-3.5\-turbo}
\label{tab:bigrams_gpt_3.5_turbo}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 1,806 \\
\textit{in the} & 1,306 \\
\textit{to the} & 820 \\
\textit{on the} & 719 \\
\textit{it is} & 706 \\
\textit{and the} & 591 \\
\textit{such as} & 555 \\
\textit{you can} & 535 \\
\textit{can be} & 496 \\
\textit{for the} & 386 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for gpt\-4}
\label{tab:unigrams_gpt_4}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{time} & 868 \\
\textit{like} & 850 \\
\textit{help} & 832 \\
\textit{data} & 830 \\
\textit{use} & 770 \\
\textit{using} & 667 \\
\textit{ai} & 663 \\
\textit{new} & 638 \\
\textit{number} & 621 \\
\textit{create} & 568 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for gpt\-4}
\label{tab:bigrams_gpt_4}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,144 \\
\textit{in the} & 1,703 \\
\textit{to the} & 1,062 \\
\textit{and the} & 939 \\
\textit{on the} & 871 \\
\textit{such as} & 807 \\
\textit{with the} & 603 \\
\textit{it is} & 568 \\
\textit{for the} & 557 \\
\textit{can be} & 553 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for koala\-13b}
\label{tab:unigrams_koala_13b}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{used} & 1,190 \\
\textit{use} & 1,185 \\
\textit{data} & 998 \\
\textit{important} & 923 \\
\textit{model} & 866 \\
\textit{time} & 780 \\
\textit{number} & 758 \\
\textit{help} & 747 \\
\textit{make} & 727 \\
\textit{using} & 696 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for koala\-13b}
\label{tab:bigrams_koala_13b}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 3,107 \\
\textit{in the} & 1,876 \\
\textit{it is} & 1,410 \\
\textit{and the} & 1,345 \\
\textit{to the} & 1,254 \\
\textit{on the} & 1,125 \\
\textit{such as} & 1,091 \\
\textit{can be} & 1,083 \\
\textit{important to} & 706 \\
\textit{you can} & 692 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for oasst\-pythia\-12b}
\label{tab:unigrams_oasst_pythia_12b}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{use} & 935 \\
\textit{used} & 754 \\
\textit{data} & 650 \\
\textit{help} & 620 \\
\textit{time} & 595 \\
\textit{important} & 589 \\
\textit{make} & 560 \\
\textit{new} & 538 \\
\textit{using} & 504 \\
\textit{create} & 495 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for oasst\-pythia\-12b}
\label{tab:bigrams_oasst_pythia_12b}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,286 \\
\textit{in the} & 1,474 \\
\textit{to the} & 977 \\
\textit{and the} & 936 \\
\textit{it is} & 812 \\
\textit{on the} & 766 \\
\textit{you can} & 743 \\
\textit{such as} & 736 \\
\textit{can be} & 704 \\
\textit{that the} & 476 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for palm\-2}
\label{tab:unigrams_palm_2}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{used} & 1,259 \\
\textit{time} & 1,154 \\
\textit{help} & 1,130 \\
\textit{use} & 1,031 \\
\textit{make} & 864 \\
\textit{way} & 821 \\
\textit{important} & 792 \\
\textit{new} & 773 \\
\textit{number} & 743 \\
\textit{people} & 716 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for palm\-2}
\label{tab:bigrams_palm_2}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,900 \\
\textit{in the} & 1,887 \\
\textit{it is} & 1,868 \\
\textit{to the} & 1,255 \\
\textit{can be} & 1,219 \\
\textit{if you} & 1,125 \\
\textit{on the} & 939 \\
\textit{you can} & 922 \\
\textit{to be} & 833 \\
\textit{and the} & 819 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Unigrams for vicuna\-13b}
\label{tab:unigrams_vicuna_13b}
\begin{tabular}{lr}
\toprule
Word & Frequency \\
\midrule
\textit{use} & 1,029 \\
\textit{used} & 909 \\
\textit{data} & 789 \\
\textit{time} & 741 \\
\textit{important} & 708 \\
\textit{help} & 706 \\
\textit{model} & 673 \\
\textit{number} & 658 \\
\textit{make} & 610 \\
\textit{using} & 605 \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[htbp]
\centering
\caption{Top 10 Bigrams for vicuna\-13b}
\label{tab:bigrams_vicuna_13b}
\begin{tabular}{lr}
\toprule
Bigram & Frequency \\
\midrule
\textit{of the} & 2,897 \\
\textit{in the} & 1,883 \\
\textit{it is} & 1,299 \\
\textit{to the} & 1,194 \\
\textit{and the} & 1,073 \\
\textit{on the} & 982 \\
\textit{such as} & 850 \\
\textit{can be} & 717 \\
\textit{you can} & 655 \\
\textit{that the} & 602 \\
\bottomrule
\end{tabular}
\end{table}
